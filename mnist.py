# -*- coding: utf-8 -*-
"""Exams.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14q0Uj6juqTv1euPahb8e8IDcHSMjuLVZ
"""

#Tensor Flow and tf.keras
import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

# Load the MNIST dataset
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

# Print the shape of the training and testing data
print("Training data shape:", x_train.shape)  # (60000, 28, 28)
print("Training labels shape:", y_train.shape)  # (60000,)
print("Testing data shape:", x_test.shape)  # (10000, 28, 28)
print("Testing labels shape:", y_test.shape)  # (10000,)
 #Display the images and labels
num_images = 10  # Number of images to display
fig, axes = plt.subplots(1, num_images, figsize=(20, 4))

for i in range(num_images):
    axes[i].imshow(x_train[i], cmap='gray')
    axes[i].set_title("Label: {}".format(y_train[i]))
    axes[i].axis('off')

plt.show()

# Reshape and normalize the input data
x_train = x_train.reshape(-1, 28, 28, 1) / 255.0
x_test = x_test.reshape(-1, 28, 28, 1) / 255.0
# Print the shape of the training and testing data
print("Training data shape:", x_train.shape)  # (60000, 28, 28, 1)
print("Training labels shape:", y_train.shape)  # (60000,)
print("Testing data shape:", x_test.shape)  # (10000, 28, 28, 1)
print("Testing labels shape:", y_test.shape)  # (10000,)

# Display an example image from the training data
plt.imshow(x_train[0].reshape(28, 28), cmap='gray')
plt.title("Label: {}".format(y_train[0]))
plt.axis('off')
plt.show()

# Define the CNN model

model = tf.keras.models.Sequential([
  tf.keras.layers.Conv2D(10, (9, 9), activation='relu', input_shape=(28, 28, 1)),
  tf.keras.layers.AveragePooling2D((2, 2)),
  tf.keras.layers.Conv2D(20, (3, 3), activation='tanh'),
  tf.keras.layers.AveragePooling2D((2, 2)),
 
  #Add Dense layers on top
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(150, activation='tanh'),
  tf.keras.layers.Dense(10, activation='sigmoid')
])

model.summary()

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

history = model.fit(x_train ,y_train, epochs=10, 
                    validation_data=(x_test, y_test))

# Make predictions
y_pred_prob = model.predict(x_test)
y_pred = np.argmax(y_pred_prob, axis=1)

# Calculate and display the confusion matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)

# Visualize the confusion matrix
plt.imshow(cm, cmap='Blues')
plt.title('Confusion Matrix')
plt.colorbar()
tick_marks = np.arange(10)
plt.xticks(tick_marks, range(10))
plt.yticks(tick_marks, range(10))
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.5, 1])
plt.legend(loc='lower right')

test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)



print(test_acc*100)

plt.plot(history.history['loss'])
plt.title('model.loss')
plt.xlabel('Epoch')
plt.ylabel('loss')

plt.legend(loc='lower right')
plt.show()